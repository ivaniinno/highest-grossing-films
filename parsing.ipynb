{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for accessing and parsing web pages\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the base url and browser for accessing websites\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "BASE_URL = \"https://en.wikipedia.org\"\n",
    "HIGHEST_GROSSING_FILMS_URL = \"/wiki/List_of_highest-grossing_films\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access page and check if it was successful\n",
    "\n",
    "page = requests.get(BASE_URL + HIGHEST_GROSSING_FILMS_URL, headers=HEADERS)\n",
    "assert page.status_code == 200, \"Failed to access page\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the page content using BeautifulSoup\n",
    "soup = BeautifulSoup(page.content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the table containing the highest grossing films\n",
    "highest_grossing_films_table = soup.find(\"table\", {\"class\": \"wikitable sortable plainrowheaders sticky-header col4right col5center col6center\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain film titles from the table, skipping the first row which contains column names \n",
    "film_titles = [highest_grossing_films_table.select(\"tr\")[i].select(\"th\")[0].a.text for i in range(1, len(highest_grossing_films_table.select(\"tr\")))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain release year for each film from the table\n",
    "film_release_years = [highest_grossing_films_table.select(\"tr\")[i].select(\"td\")[3].text.strip() for i in range(1, len(highest_grossing_films_table.select(\"tr\")))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need link for each film to p=obtain some specific information for each film\n",
    "film_links = [BASE_URL + highest_grossing_films_table.select(\"tr\")[i].select(\"th\")[0].a.get(\"href\") for i in range(1, len(highest_grossing_films_table.select(\"tr\")))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of directors and extract the director(s) for each film\n",
    "directors = []\n",
    "\n",
    "for link in film_links:\n",
    "    # Access film page and search for directors\n",
    "    film_page = requests.get(link, headers=HEADERS)\n",
    "    film_soup = BeautifulSoup(film_page.content, \"lxml\")\n",
    "    # Extract target element\n",
    "    raw_string_director = film_soup.find(\"th\", string=\"Directed by\").find_next_sibling(\"td\").text\n",
    "    # Clean up the string and split it into a list\n",
    "    \n",
    "    # Delete references and special symbols and add commas between names\n",
    "    current_directors = re.sub(r'([a-z])([A-Z])',  r'\\1,\\2', re.sub(r'\\[\\d+\\]', \",\", raw_string_director.replace(\"\\n\", \"\")))\n",
    "    \n",
    "    # If the last character is a comma, remove it\n",
    "    if current_directors[-1] == \",\":\n",
    "        current_directors = current_directors[:-1]\n",
    "        \n",
    "    # Split the string into a list of directors\n",
    "    current_directors = current_directors.split(\",\")\n",
    "    \n",
    "    directors.append(current_directors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain revenues for each film from the table \n",
    "films_box_office_revenues = [re.sub(r'^.*\\$', '$', highest_grossing_films_table.select(\"tr\")[i].select(\"td\")[2].text.strip()) for i in range(1, len(highest_grossing_films_table.select(\"tr\")))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find country for each film accessing its web page\n",
    "film_countries = []\n",
    "\n",
    "for link in film_links:\n",
    "    film_page = requests.get(link, headers=HEADERS)\n",
    "    film_soup = BeautifulSoup(film_page.content, \"lxml\")\n",
    "    # Find \"country\" or \"countries\" element and access its neighbor\n",
    "    country_td = film_soup.find(\"th\", string=re.compile(r\"Country|Countries\")).find_next_sibling(\"td\")\n",
    "    \n",
    "    # If we see Unordered List, we will extract countries from it\n",
    "    if country_td.find(\"ul\"):\n",
    "    # Extract every country from the list\n",
    "        current_countries = [li.get_text() for li in country_td.find_all(\"li\")]\n",
    "    \n",
    "    # IF there is no list, we will extract countries directly\n",
    "    else:\n",
    "        current_countries = country_td.get_text(\",\", strip=True).split(\",\")\n",
    "    \n",
    "    # Clean string from references and special symbols and separate when seeing a capital letter after a lowercase letter\n",
    "    current_countries = [re.sub(r'([a-z])([A-Z])',  r'\\1,\\2', re.sub(r'\\[\\d+\\]', '', current_country.replace(\"\\n\", \"\"))) for current_country in current_countries]\n",
    "    \n",
    "    film_countries.append(current_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data manipulation and storage\n",
    "import sqlite3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a database and create a cursor for interacting with it\n",
    "connection = sqlite3.connect(\"films.db\")\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1270b73c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query to create a table for storing film data\n",
    "create_films_table = \"\"\"CREATE TABLE IF NOT EXISTS \n",
    "films(\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    title TEXT NOT NULL,\n",
    "    release_year INTEGER,\n",
    "    director TEXT,\n",
    "    box_office_revenue TEXT,\n",
    "    country TEXT\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "cursor.execute(create_films_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into the table\n",
    "for title, release_year, directors, revenue, country in zip(film_titles, film_release_years, directors, films_box_office_revenues, film_countries):\n",
    "    cursor.execute(\"INSERT INTO films (title, release_year, director, box_office_revenue, country) VALUES (?, ?, ?, ?, ?)\", (title, release_year, \", \".join(directors), revenue, \", \".join(country)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the table\n",
    "cursor.execute(\"SELECT * FROM films\")\n",
    "\n",
    "# Fetch data from the cursor\n",
    "films_data = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain column names\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "\n",
    "# Transform films_data into a list of dictionaries (JSON format)\n",
    "films_list = [dict(zip(column_names, film)) for film in films_data]\n",
    "\n",
    "# Write film data to a JSON file\n",
    "with open(\"films.json\", \"w\") as file:\n",
    "    json.dump(films_list, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
